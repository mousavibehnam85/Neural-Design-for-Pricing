import pandas as pd
import numpy as np

# Generate Synthetic House Price Data
np.random.seed(42)

num_samples = 1000
area = np.random.randint(500, 3000, num_samples)
bedrooms = np.random.randint(1, 6, num_samples)
location = np.random.choice(['Urban', 'Suburban', 'Rural'], num_samples)

# Initialize price with area's relationship
price = area.copy()

# Multiply price based on location
for i in range(len(location)):
    if location[i] == 'Rural':
        price[i] *= 1
    elif location[i] == 'Suburban':
        price[i] *= 4
    else:  # Urban
        price[i] *= 9

# Add $50,000 per bedroom to the price
price += (bedrooms * 25000)

# Create DataFrame
data = {
    'Area': area,
    'Bedrooms': bedrooms,
    'Location': location,
    'Price': price
}

# Data Storage: Save the synthetic data into a CSV file
house_price_data = pd.DataFrame(data)
house_price_data.to_csv('house_price_data.csv', index=False)

# Working with Data: Load and Explore
house_price_data = pd.read_csv('house_price_data.csv')

# Explore the dataset
with open('house_price_data_info.txt', 'w') as file:
    file.write("Data Information:\n")
    house_price_data.info(buf=file)

# Additional analysis and processing
# ... (followed by data preprocessing, model building, etc.)



### X matrix will have three elements of area, bedrooms and location to predict y
### the relation between columns of X and non-linear effects will be considered


import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# Load the data
house_price_data = pd.read_csv('house_price_data.csv')

# Mapping for replacing values
location_mapping = {'Rural': 1, 'Suburban': 2, 'Urban': 3}

# Replace values in the 'Location' column
house_price_data['Location'] = house_price_data['Location'].replace(location_mapping)
house_price_data.to_csv('house_price_data.csv', index=False)


# Create the feature matrix X and target variable y
X = house_price_data[['Area', 'Bedrooms', 'Location']]
y = house_price_data['Price']

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Neural Network architecture
model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),#input_shape=(X_train.shape[1], trains based on the 3 columns
    tf.keras.layers.Dense(64, activation='selu'),
    tf.keras.layers.Dense(3, activation='relu'),  # Output layer (regression, so one output neuron)
    tf.keras.layers.Dense(1)
])
#Relu an activation function that introduces non-linearity to the model by allowing the model to learn complex patterns in the data. 
#ReLU activation is commonly used and helps the network learn and model more complex relationships within the data.
#in    tf.keras.layers.Dense(64.... first layer there is 64 neurons in one layer each connected to all the inputs



# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')
#Here are the key features of the Adam optimizer:
## Adaptive Learning Rate: Adam adjusts the learning rates for each parameter
## Momentum: It utilizes the concept of momentum to help accelerate convergence
## Bias Correction: Adam performs bias correction during the initial time steps to correct the estimates of the first and second moments, preventing large moments at first cycles
## RELU is for convergence and SELU for self normalizing compared to other neurons


# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=1, verbose=1)

# Evaluate the model
mse = model.evaluate(X_test, y_test)
print(f"Mean Squared Error(SQRT): {np.sqrt(mse)}")

# Make predictions
y_pred = model.predict(X_test)

# Save predictions to a file (optional)
predictions = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})
predictions.to_csv('house_price_predictions_nn.csv', index=False)
